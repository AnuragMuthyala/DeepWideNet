{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepWideNet",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyFA0mOn-0Gr"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as f\n",
        "\n",
        "import requests\n",
        "from zipfile import ZipFile"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZD0ErHO_vt5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d33139d4-b236-4c46-9bbe-2061aa4c149c"
      },
      "source": [
        "json = requests.get('https://files.grouplens.org/datasets/movielens/ml-100k.zip', allow_redirects=True)\n",
        "open('dataset.zip', 'wb').write(json.content) \n",
        "\n",
        "with ZipFile('dataset.zip', 'r') as zip:\n",
        "    zip.printdir()\n",
        "  \n",
        "    print('Extracting all the files now...')\n",
        "    zip.extractall()\n",
        "    print('Done!')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File Name                                             Modified             Size\n",
            "ml-100k/                                       2016-01-29 14:26:28            0\n",
            "ml-100k/allbut.pl                              2000-07-19 16:09:28          716\n",
            "ml-100k/mku.sh                                 2000-07-19 16:09:28          643\n",
            "ml-100k/README                                 2016-01-29 14:26:28         6750\n",
            "ml-100k/u.data                                 2000-07-19 16:09:30      1979173\n",
            "ml-100k/u.genre                                2000-07-19 16:09:30          202\n",
            "ml-100k/u.info                                 2000-07-19 16:09:30           36\n",
            "ml-100k/u.item                                 2000-07-19 16:09:30       236344\n",
            "ml-100k/u.occupation                           2000-07-19 16:09:30          193\n",
            "ml-100k/u.user                                 2000-07-19 16:09:30        22628\n",
            "ml-100k/u1.base                                2001-03-08 12:33:08      1586544\n",
            "ml-100k/u1.test                                2001-03-08 12:32:56       392629\n",
            "ml-100k/u2.base                                2001-03-08 12:33:24      1583948\n",
            "ml-100k/u2.test                                2001-03-08 12:33:12       395225\n",
            "ml-100k/u3.base                                2001-03-08 12:33:38      1582546\n",
            "ml-100k/u3.test                                2001-03-08 12:33:26       396627\n",
            "ml-100k/u4.base                                2001-03-08 12:33:52      1581878\n",
            "ml-100k/u4.test                                2001-03-08 12:33:40       397295\n",
            "ml-100k/u5.base                                2001-03-08 12:34:04      1581776\n",
            "ml-100k/u5.test                                2001-03-08 12:33:54       397397\n",
            "ml-100k/ua.base                                2001-03-08 12:34:18      1792501\n",
            "ml-100k/ua.test                                2001-03-08 12:34:18       186672\n",
            "ml-100k/ub.base                                2001-03-08 12:34:34      1792476\n",
            "ml-100k/ub.test                                2001-03-08 12:34:36       186697\n",
            "Extracting all the files now...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpF8_Lfu9EfR"
      },
      "source": [
        "class RatingMatrix:\n",
        "\n",
        "  def __init__(self, train=True):\n",
        "\n",
        "    self.__ext = '.base'\n",
        "    if not train:\n",
        "      self.__ext = '.test'\n",
        "    l = [i for i in range(1, 6)]\n",
        "    self.__data = []\n",
        "    self.__labels = []\n",
        "    self.__next = 0\n",
        "\n",
        "    for i in l:\n",
        "      with open('ml-100k/u'+str(i)+self.__ext) as o:\n",
        "        while True:\n",
        "          line = o.readline()\n",
        "          if not line:\n",
        "            break\n",
        "          toks = line.split('\\t')\n",
        "          self.__data.append([int(toks[0])-1, int(toks[1])-1])\n",
        "          self.__labels.append(float(toks[2]))\n",
        "\n",
        "  def __iter__(self):\n",
        "    self.__next = 0\n",
        "    return self\n",
        "\n",
        "  def __next__(self):\n",
        "    if self.__next == len(self.__data):\n",
        "      self.__next = 0\n",
        "      raise StopIteration\n",
        "    val = (self.__data[self.__next], self.__labels[self.__next])\n",
        "    self.__next += 1\n",
        "    return val\n",
        "\n",
        "class LatentFactors:\n",
        "\n",
        "  def __init__(self, users, items):\n",
        "    self.__users = users\n",
        "    self.__items = items\n",
        "    self.__user_lf = torch.rand(users, 100)\n",
        "    self.__item_lf = torch.rand(items, 100)\n",
        "\n",
        "  def get(self, user, item):\n",
        "    third = torch.cat((self.__user_lf[user], self.__item_lf[item]), 0)\n",
        "    return third\n",
        "  \n",
        "  def backward(self, user, item, gradient):\n",
        "    self.__user_lf[user] -= 0.01*gradient[0]\n",
        "    self.__item_lf[item] -= 0.01*gradient[1]\n",
        "\n",
        "train_data = RatingMatrix(train=True)\n",
        "lf = LatentFactors(943, 1682)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiWFaGBVAP1v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c46bce21-8376-40cf-def1-531f53acdac4"
      },
      "source": [
        "class LimiterFunction(torch.autograd.Function):\n",
        "\n",
        "  def forward(ctx, input):\n",
        "    ctx.save_for_backward(input)\n",
        "    return input.clamp(min=0, max=5)\n",
        "\n",
        "  def backward(ctx, grad_output):\n",
        "    input, = ctx.saved_tensors\n",
        "    grad_input = grad_output.clone()\n",
        "    grad_input[input < 0] = 0\n",
        "    grad_input[input > 5] = 0\n",
        "    return grad_input\n",
        "\n",
        "class DeepWideNet(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(DeepWideNet, self).__init__()\n",
        "    \n",
        "    self.l1 = nn.Linear(200, 100)\n",
        "    self.l2 = nn.Linear(100, 50)\n",
        "    self.l3 = nn.Linear(50, 25)\n",
        "    self.l4 = nn.Linear(25, 1)\n",
        "\n",
        "    self.limiter = LimiterFunction.apply\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    x = f.relu(self.l1(x))\n",
        "    x = f.relu(self.l2(x))\n",
        "    x = f.relu(self.l3(x))\n",
        "    x = self.limiter(self.l4(x))\n",
        "    return x\n",
        "\n",
        "device = torch.device(\"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda:0\")\n",
        "\n",
        "net = DeepWideNet()\n",
        "net.to(device)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeepWideNet(\n",
              "  (l1): Linear(in_features=200, out_features=100, bias=True)\n",
              "  (l2): Linear(in_features=100, out_features=50, bias=True)\n",
              "  (l3): Linear(in_features=50, out_features=25, bias=True)\n",
              "  (l4): Linear(in_features=25, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ri6oLJ_DAmn"
      },
      "source": [
        "loss = nn.MSELoss()\n",
        "opt = torch.optim.SGD(net.parameters(), lr=0.01)\n",
        "epochs = 10\n",
        "count = 0\n",
        "running_loss = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  count = 0\n",
        "\n",
        "  for (X, Y) in train_data:\n",
        "    #print(X, Y)\n",
        "    x = lf.get(X[0], X[1])\n",
        "    x = x.to(device)\n",
        "    opt.zero_grad()\n",
        "    \n",
        "    pred = net(x)\n",
        "    act = torch.tensor([Y]).to(device)\n",
        "    out = loss(pred, act)\n",
        "    running_loss += out.item()\n",
        "    out.backward()\n",
        "    #p_l = list(net.parameters())\n",
        "    #gr = torch.matmul(p_l[0].T, p_l[1].grad)\n",
        "    #lf.backward(X[0], X[1], gr.view(-1, 100))\n",
        "    opt.step()\n",
        "    count += 1\n",
        "  #print(running_loss/count)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(running_loss/count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4znJEe5ujqy",
        "outputId": "eed5a557-63df-44b5-9d6e-e7ac2980365b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.1623523795302302\n"
          ]
        }
      ]
    }
  ]
}